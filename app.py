import streamlit as st
from llama_index import VectorStoreIndex, ServiceContext, Document
from llama_index.llms import OpenAI
import openai
from llama_index import SimpleDirectoryReader

st.set_page_config(page_title="Chat with the Streamlit docs, powered by LlamaIndex", page_icon="ğŸ¦™", layout="centered", initial_sidebar_state="auto", menu_items=None)
openai.api_key = st.secrets.OpenAIAPI.openai_api_key
st.title("æ•™å¸«ChatBotã‚¢ãƒ—ãƒª")
         
if "messages" not in st.session_state.keys(): # Initialize the chat messages history
    st.session_state.messages = [
        {"role": "assistant", "content": "ã“ã‚“ã«ã¡ã¯ï¼ç§ã¯è³ªå•ã«å¯¾ã—ã¦ã€è§£èª¬ã¨ç¢ºèªã‚¯ã‚¤ã‚ºã‚’å‡ºã™ChatBotã§ã™ã€‚ä½•ã§ã‚‚è³ªå•ã—ã¦ãã ã•ã„ï¼"}
    ]

@st.cache_resource(show_spinner=False)
# ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¨ã‚„ã‚Šã¨ã‚Šã™ã‚‹é–¢æ•°
def load_data():
    with st.spinner(text="ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„"):
        reader = SimpleDirectoryReader(input_dir="./data", recursive=True)
        docs = reader.load_data()
        service_context = ServiceContext.from_defaults(llm=OpenAI(model="gpt-3.5-turbo", temperature=0.5, system_prompt="""
        {ãƒ†ãƒ¼ãƒ} = ã€Œå®‰é”ã¨ã—ã¾ã‚€ã‚‰ã€ã¨ã€Œç¾ä»£å“²å­¦ã€ 

ã‚ãªãŸã¯{ãƒ†ãƒ¼ãƒ}ã®å°‚é–€å®¶ã§ã™ã€‚{ãƒ†ãƒ¼ãƒ}ã®ç†è§£ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ãŸã‚ã®4æŠå•é¡Œã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚ ã¯ã˜ã‚ã«åˆç´šãƒ¬ãƒ™ãƒ«ã®å•é¡Œã‹ã‚‰å§‹ã‚ã€æ­£ã—ã„å›ç­”ãŒå¾—ã‚‰ã‚Œã‚‹ãŸã³ã«å•é¡Œã®é›£æ˜“åº¦ã‚’å¾ã€…ã«ä¸Šã’ã¦ãã ã•ã„ã€‚ 

ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚
ãƒ»ã‚ãªãŸãŒå‡ºé¡Œ 
ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­” 
ãƒ»ã‚ãªãŸãŒæ­£è§£ã®ç™ºè¡¨åŠã³æ¬¡ã®å‡ºé¡Œ 
ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­” 
ãƒ»ã‚ãªãŸãŒæ­£è§£ã®ç™ºè¡¨åŠã³æ¬¡ã®å‡ºé¡Œ 
ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­” 
... 
ä»¥ä¸‹åŒæ§˜ã«ç¹°ã‚Šè¿”ã™

ã¨ã„ã†æµã‚Œã§é€²ã¿ã¾ã™ã€‚ ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã€ã€ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”ã€ã®éƒ¨åˆ†ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã™ã‚‹éƒ¨åˆ†ã§ã™ã€‚ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’å¾…ã¡ã¾ã™ã€‚

        """))
        index = VectorStoreIndex.from_documents(docs, service_context=service_context)
        return index
             
index = load_data()


if "chat_engine" not in st.session_state.keys(): # Initialize the chat engine
        st.session_state.chat_engine = index.as_chat_engine(chat_mode="condense_question", verbose=True)

if prompt := st.chat_input("Your question"): # Prompt for user input and save to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})

for message in st.session_state.messages: # Display the prior chat messages
    with st.chat_message(message["role"]):
        st.write(message["content"])

# If last message is not from assistant, generate a new response
if st.session_state.messages[-1]["role"] != "assistant":
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            response = st.session_state.chat_engine.chat(prompt)
            st.write(response.response)
            message = {"role": "assistant", "content": response.response}
            st.session_state.messages.append(message) # Add response to message history
