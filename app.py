import streamlit as st
from llama_index import VectorStoreIndex, ServiceContext, Document
from llama_index.llms import OpenAI
import openai
from llama_index import SimpleDirectoryReader

st.set_page_config(page_title="Chat with the Streamlit docs, powered by LlamaIndex", page_icon="ğŸ¦™", layout="centered", initial_sidebar_state="auto", menu_items=None)
openai.api_key = st.secrets.OpenAIAPI.openai_api_key
st.title("æ•™å¸«ChatBotã‚¢ãƒ—ãƒª")

if "messages" not in st.session_state.keys(): # Initialize the chat messages history
    st.session_state.messages = [
        {"role": "assistant", "content": "ã“ã‚“ã«ã¡ã¯ï¼ç§ã¯ã‚¯ã‚¤ã‚ºã‚’å‡ºã™ChatBotã§ã™ã€‚ä½•ã§ã‚‚è³ªå•ã—ã¦ãã ã•ã„ï¼"}
    ]
    
mode = st.radio(
    "è³ªå•ãƒ¢ãƒ¼ãƒ‰ã¨å›ç­”ãƒ¢ãƒ¼ãƒ‰ã‚’åˆ‡ã‚Šæ›¿ãˆã¦ãŠä½¿ã„ãã ã•ã„",
    ["***å‡ºé¡Œ***", "***å›ç­”***"],
    horizontal = True)

if mode == "***å›ç­”***":
  st.text("1")
  @st.cache_resource(show_spinner=False)
  # ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¨ã‚„ã‚Šã¨ã‚Šã™ã‚‹é–¢æ•°
  def load_data():
      st.text("2")
      with st.spinner(text="ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„"):
          reader = SimpleDirectoryReader(input_dir="./data", recursive=True)
          st.text("3")
          docs = reader.load_data()
          st.text("4")
          service_context = ServiceContext.from_defaults(llm=OpenAI(model="gpt-3.5-turbo", temperature=0.5, system_prompt="""
          {ãƒ†ãƒ¼ãƒ} = ã€Œå®‰é”ã¨ã—ã¾ã‚€ã‚‰ã€ã¨ã€Œç¾ä»£å“²å­¦ã€ 
          
          ã‚ãªãŸã¯{ãƒ†ãƒ¼ãƒ}ã®å°‚é–€å®¶ã§ã™ã€‚è³ªå•ã«å¯¾ã—ã¦è©³ç´°ãªèª¬æ˜ã‚’ã—ã¦ãã ã•ã„ã€‚
          """))
          st.text("5")
          index = VectorStoreIndex.from_documents(docs, service_context=service_context)
          st.text("6")
          return index


  index = load_data()
  st.text("ã‚„ã»")

  if "chat_engine" not in st.session_state.keys(): # Initialize the chat engine
          st.session_state.chat_engine = index.as_chat_engine(chat_mode="condense_question", verbose=True)

  if prompt := st.chat_input("Your question"): # Prompt for user input and save to chat history
      st.session_state.messages.append({"role": "user", "content": prompt})

  for message in st.session_state.messages: # Display the prior chat messages
      with st.chat_message(message["role"]):
          st.write(message["content"])

  # If last message is not from assistant, generate a new response
  if st.session_state.messages[-1]["role"] != "assistant":
      with st.chat_message("assistant"):
          with st.spinner("è€ƒãˆä¸­..."):
              response = st.session_state.chat_engine.chat(prompt)
              st.write(response.response)
              message = {"role": "assistant", "content": response.response}
              st.session_state.messages.append(message) # Add response to message history
else:
  st.text("ããŸã‚ˆ")
